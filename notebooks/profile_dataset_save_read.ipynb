{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling of `maze_dataset` serializing/loading/saving/reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import warnings\n",
    "from typing import Any, Callable, Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from muutils.statcounter import StatCounter\n",
    "from muutils.timeit_fancy import FancyTimeitResult, timeit_fancy\n",
    "\n",
    "from maze_dataset import (\n",
    "\tMazeDataset,\n",
    "\tMazeDatasetConfig,\n",
    "\tset_serialize_minimal_threshold,\n",
    ")\n",
    "from maze_dataset.generation.generators import GENERATORS_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs: list[MazeDatasetConfig] = [\n",
    "\tMazeDatasetConfig(\n",
    "\t\tname=\"test\",\n",
    "\t\tgrid_n=grid_n,\n",
    "\t\tn_mazes=n_mazes,\n",
    "\t\tmaze_ctor=GENERATORS_MAP[\"gen_dfs\"],\n",
    "\t)\n",
    "\tfor grid_n, n_mazes in itertools.product(\n",
    "\t\t[10],\n",
    "\t\tnp.logspace(1, 2, 2, dtype=int).tolist(),  # 100, for CI tests\n",
    "\t\t# np.logspace(1, 3, 5, dtype=int).tolist(), # 1k\n",
    "\t\t# np.logspace(0, 4, 9, dtype=int).tolist(), # 10k, notebook results from this set\n",
    "\t)\n",
    "]\n",
    "\n",
    "datasets: list[MazeDataset] = [\n",
    "\tMazeDataset.from_config(cfg, load_local=False) for cfg in cfgs\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns: list[str] = [\n",
    "\t\"grid_n\",\n",
    "\t\"n_mazes\",\n",
    "\t\"serialize\",\n",
    "\t\"serialize_minimal\",\n",
    "\t\"load\",\n",
    "\t\"load_minimal\",\n",
    "\t\"save\",\n",
    "\t\"save_minimal\",\n",
    "\t\"read\",\n",
    "\t\"read_minimal\",\n",
    "]\n",
    "speeds_data: list[dict] = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_timeit_fancy(\n",
    "\tname: str,\n",
    "\tfunction: Callable,\n",
    "\tdo_profiling: bool,\n",
    "\trepeats: int,\n",
    "\ttiming_stat: Callable[[StatCounter], float],\n",
    ") -> tuple[dict, Any]:\n",
    "\toutput: dict = dict()\n",
    "\n",
    "\tresult: FancyTimeitResult = timeit_fancy(\n",
    "\t\tfunction,\n",
    "\t\tget_return=True,\n",
    "\t\tdo_profiling=do_profiling,\n",
    "\t\trepeats=repeats,\n",
    "\t)\n",
    "\n",
    "\toutput[name] = timing_stat(result.timings)\n",
    "\toutput[f\"{name}:stats\"] = result.timings\n",
    "\tif do_profiling:\n",
    "\t\toutput[f\"{name}:profiling\"] = result.profile\n",
    "\n",
    "\treturn output, result.return_value\n",
    "\n",
    "\n",
    "def measure_dataset_speed(\n",
    "\td: MazeDataset,\n",
    "\tdo_profiling: bool = True,\n",
    "\trepeats: int = 1,\n",
    "\ttiming_stat: Callable[[StatCounter], float] = StatCounter.min,\n",
    ") -> dict:\n",
    "\tif repeats > 1:\n",
    "\t\twarnings.warn(\n",
    "\t\t\t\"Repeats > 1, results might not be accurate due to generation metadata being collected.\",\n",
    "\t\t)\n",
    "\tkwargs_fancy_timeit: dict = dict(\n",
    "\t\tdo_profiling=do_profiling,\n",
    "\t\ttiming_stat=timing_stat,\n",
    "\t\trepeats=repeats,\n",
    "\t)\n",
    "\tset_serialize_minimal_threshold(None)\n",
    "\t_d_cpy: MazeDataset = copy.deepcopy(d)\n",
    "\t# set up row data\n",
    "\trow_data: dict = dict(\n",
    "\t\tgrid_n=d.cfg.grid_n,\n",
    "\t\tn_mazes=d.cfg.n_mazes,\n",
    "\t)\n",
    "\t# serialization & loading\n",
    "\tinfo_serialize, result_serialize = wrapped_timeit_fancy(\n",
    "\t\t\"serialize_full\",\n",
    "\t\t_d_cpy._serialize_full,\n",
    "\t\t**kwargs_fancy_timeit,\n",
    "\t)\n",
    "\trow_data.update(info_serialize)\n",
    "\t_d_cpy = copy.deepcopy(d)\n",
    "\n",
    "\tinfo_serialize_min, result_serialize_min = wrapped_timeit_fancy(\n",
    "\t\t\"serialize_minimal\",\n",
    "\t\t_d_cpy._serialize_minimal,\n",
    "\t\t**kwargs_fancy_timeit,\n",
    "\t)\n",
    "\trow_data.update(info_serialize_min)\n",
    "\t_d_cpy = copy.deepcopy(d)\n",
    "\n",
    "\t# info_serialize_min_alt, result_serialize_min_alt = wrapped_timeit_fancy(\n",
    "\t#     'serialize_minimal_alt', _d_cpy._serialize_minimal_alt, **kwargs_fancy_timeit\n",
    "\t# )\n",
    "\t# row_data.update(info_serialize_min_alt)\n",
    "\t_d_cpy = copy.deepcopy(d)\n",
    "\tinfo_serialize_cat, result_serialize_cat = wrapped_timeit_fancy(\n",
    "\t\t\"serialize_minimal_soln_cat\",\n",
    "\t\t_d_cpy._serialize_minimal_soln_cat,\n",
    "\t\t**kwargs_fancy_timeit,\n",
    "\t)\n",
    "\trow_data.update(info_serialize_cat)\n",
    "\t_d_cpy = copy.deepcopy(d)\n",
    "\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"load_legacy\",\n",
    "\t\t\tlambda: MazeDataset._load_legacy(result_serialize),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"load_full\",\n",
    "\t\t\tlambda: MazeDataset._load_full(result_serialize),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"load_minimal\",\n",
    "\t\t\tlambda: MazeDataset._load_minimal(result_serialize_min),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"load_minimal_soln_cat\",\n",
    "\t\t\tlambda: MazeDataset._load_minimal_soln_cat(result_serialize_cat),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"load_full\",\n",
    "\t\t\tlambda: MazeDataset._load_full(result_serialize),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"load_minimal\",\n",
    "\t\t\tlambda: MazeDataset._load_minimal(result_serialize_min),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"load_minimal_soln_cat\",\n",
    "\t\t\tlambda: MazeDataset._load_minimal_soln_cat(result_serialize_cat),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\n",
    "\t# saving and loading\n",
    "\tpath_default: str = f\"../data/{d.cfg.to_fname()}.zanj\"\n",
    "\tpath_min: str = f\"../data/{d.cfg.to_fname()}_min.zanj\"\n",
    "\n",
    "\t# default\n",
    "\tset_serialize_minimal_threshold(None)\n",
    "\t_d_cpy = copy.deepcopy(d)\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"save\",\n",
    "\t\t\tlambda: _d_cpy.save(file_path=path_default),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\t_d_cpy = copy.deepcopy(d)\n",
    "\n",
    "\t# read_legacy\n",
    "\tset_serialize_minimal_threshold(-1)\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"read_legacy\",\n",
    "\t\t\tlambda: MazeDataset.read(file_path=path_default),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\n",
    "\t# default read\n",
    "\tset_serialize_minimal_threshold(None)\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"read\",\n",
    "\t\t\tlambda: MazeDataset.read(file_path=path_default),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\n",
    "\t# minimal\n",
    "\tset_serialize_minimal_threshold(0)\n",
    "\t_d_cpy = copy.deepcopy(d)\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"save_minimal\",\n",
    "\t\t\tlambda: _d_cpy.save(file_path=path_min),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\t_d_cpy = copy.deepcopy(d)\n",
    "\n",
    "\trow_data.update(\n",
    "\t\twrapped_timeit_fancy(\n",
    "\t\t\t\"read_minimal\",\n",
    "\t\t\tlambda: MazeDataset.read(file_path=path_min),\n",
    "\t\t\t**kwargs_fancy_timeit,\n",
    "\t\t)[0],\n",
    "\t)\n",
    "\n",
    "\t# asserts\n",
    "\t# assert d == read_default\n",
    "\t# assert d == read_minimal\n",
    "\n",
    "\t# reset cfg?\n",
    "\tset_serialize_minimal_threshold(None)\n",
    "\n",
    "\treturn row_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(datasets):\n",
    "\tprint(f\"Profiling {i + 1}/{len(datasets)}:\\t{d.cfg}\")\n",
    "\tresult = measure_dataset_speed(d)\n",
    "\tspeeds_data.append(result)\n",
    "\tcols_short: str = str({k: v for k, v in result.items() if \":\" not in k})\n",
    "\tprint(f\"\\t{cols_short}\")\n",
    "\tprint(f\"\\t{d.cfg!s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEEDS: pd.DataFrame = pd.DataFrame(speeds_data)\n",
    "\n",
    "SPEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_speedups(speeds: pd.DataFrame) -> pd.DataFrame:\n",
    "\t# for prefix in column_measurement_prefixes:\n",
    "\t#     speeds[f'{prefix}_speedup'] = speeds[f'{prefix}_full'] / speeds[f'{prefix}_minimal']\n",
    "\tspeeds[\"serialize/speedup\"] = speeds[\"serialize_full\"] / speeds[\"serialize_minimal\"]\n",
    "\tspeeds[\"load/speedup\"] = speeds[\"load_full\"] / speeds[\"load_minimal\"]\n",
    "\tspeeds[\"save/speedup\"] = speeds[\"save\"] / speeds[\"save_minimal\"]\n",
    "\tspeeds[\"read/speedup\"] = speeds[\"read\"] / speeds[\"read_minimal\"]\n",
    "\n",
    "\treturn speeds\n",
    "\n",
    "\n",
    "SPEEDS = compute_speedups(SPEEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEEDS: pd.DataFrame = pd.DataFrame(speeds_data)\n",
    "\n",
    "# SPEEDS.loc[:,\"load_legacy\":\"load_minimal_soln_cat:profiling\"]\n",
    "SPEEDS.loc[:, \"read_legacy\":\"read:profiling\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEEDS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_speedups(speeds: pd.DataFrame) -> pd.DataFrame:\n",
    "\t# for prefix in column_measurement_prefixes:\n",
    "\t#     speeds[f'{prefix}_speedup'] = speeds[f'{prefix}_full'] / speeds[f'{prefix}_minimal']\n",
    "\tspeeds[\"serialize/speedup\"] = speeds[\"serialize_full\"] / speeds[\"serialize_minimal\"]\n",
    "\tspeeds[\"load_minimal/speedup\"] = speeds[\"load_legacy\"] / speeds[\"load_minimal\"]\n",
    "\tspeeds[\"load/speedup\"] = speeds[\"load_legacy\"] / speeds[\"load_full\"]\n",
    "\tspeeds[\"save/speedup\"] = speeds[\"save\"] / speeds[\"save_minimal\"]\n",
    "\tspeeds[\"read_minimal/speedup\"] = speeds[\"read_legacy\"] / speeds[\"read_minimal\"]\n",
    "\tspeeds[\"read/speedup\"] = speeds[\"read_legacy\"] / speeds[\"read\"]\n",
    "\n",
    "\treturn speeds\n",
    "\n",
    "\n",
    "SPEEDS = compute_speedups(SPEEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEEDS[[c for c in SPEEDS.columns if \":\" not in c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_speeds(\n",
    "\tspeeds: pd.DataFrame,\n",
    "\tcolumn_measurement_prefixes: Sequence[str] = (\"serialize\", \"load\", \"save\", \"read\"),\n",
    ") -> None:\n",
    "\tn_measurements: int = len(column_measurement_prefixes)\n",
    "\tfig, axs = plt.subplots(2, n_measurements, figsize=(n_measurements * 5, 10))\n",
    "\n",
    "\tunique_grid_ns: list[int] = speeds[\"grid_n\"].unique().tolist()\n",
    "\n",
    "\tfor i, prefix in enumerate(column_measurement_prefixes):\n",
    "\t\tprint(f\"Plotting {prefix} timings and speedups\")\n",
    "\t\tfor grid_n in unique_grid_ns:\n",
    "\t\t\tprint(f\"Plotting grid_n={grid_n}\")\n",
    "\t\t\t# raw timings\n",
    "\t\t\tax_timings = axs[0, i]\n",
    "\t\t\tspeeds_masked = speeds[speeds[\"grid_n\"] == grid_n].sort_values(\"n_mazes\")\n",
    "\t\t\tx_n_mazes = speeds_masked[\"n_mazes\"]\n",
    "\n",
    "\t\t\t# Plotting\n",
    "\t\t\tfor col in speeds_masked.columns:\n",
    "\t\t\t\tif (prefix in col) and (\"speedup\" not in col) and (\":\" not in col):\n",
    "\t\t\t\t\tax_timings.plot(\n",
    "\t\t\t\t\t\tx_n_mazes,\n",
    "\t\t\t\t\t\tspeeds_masked[col],\n",
    "\t\t\t\t\t\t\"x-\",\n",
    "\t\t\t\t\t\tlabel=f\"grid_n={grid_n}, {col}\",\n",
    "\t\t\t\t\t)\n",
    "\n",
    "\t\t\t# Setting multiple properties with `set`\n",
    "\t\t\tax_timings.set(\n",
    "\t\t\t\txscale=\"log\",\n",
    "\t\t\t\tyscale=\"log\",\n",
    "\t\t\t\txlabel=\"Number of mazes\",\n",
    "\t\t\t\tylabel=\"Runtime [sec]\",\n",
    "\t\t\t\ttitle=f\"{prefix} timings\",\n",
    "\t\t\t)\n",
    "\t\t\tax_timings.legend()\n",
    "\n",
    "\t\t\t# speedups\n",
    "\t\t\tax_speedups = axs[1, i]\n",
    "\t\t\tcol_name: str = (\n",
    "\t\t\t\tf\"{prefix}\" if prefix in (\"serialize\", \"save\") else f\"{prefix}_minimal\"\n",
    "\t\t\t)\n",
    "\t\t\tax_speedups.plot(\n",
    "\t\t\t\tx_n_mazes,\n",
    "\t\t\t\tspeeds_masked[f\"{col_name}/speedup\"],\n",
    "\t\t\t\t\"x-\",\n",
    "\t\t\t\tlabel=f\"grid_n={grid_n}\",\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# Setting multiple properties with `set` for ax_speedups\n",
    "\t\t\tax_speedups.set(\n",
    "\t\t\t\txscale=\"log\",\n",
    "\t\t\t\tyscale=\"log\",\n",
    "\t\t\t\txlabel=\"Number of mazes\",\n",
    "\t\t\t\tylabel=\"Speedup\",\n",
    "\t\t\t\ttitle=f\"{col_name} speedups\",\n",
    "\t\t\t)\n",
    "\t\t\tax_speedups.plot(\n",
    "\t\t\t\tx_n_mazes,\n",
    "\t\t\t\tspeeds_masked[f\"{prefix}/speedup\"],\n",
    "\t\t\t\t\"x-\",\n",
    "\t\t\t\tlabel=f\"grid_n={grid_n}\",\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# Setting multiple properties with `set` for ax_speedups\n",
    "\t\t\tax_speedups.set(\n",
    "\t\t\t\txscale=\"log\",\n",
    "\t\t\t\tyscale=\"log\",\n",
    "\t\t\t\txlabel=\"Number of mazes\",\n",
    "\t\t\t\tylabel=\"Speedup\",\n",
    "\t\t\t\ttitle=f\"{prefix} speedups\",\n",
    "\t\t\t)\n",
    "\t\t\tax_speedups.legend()\n",
    "\n",
    "\n",
    "plot_speeds(SPEEDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speedups plotted on the bottom set of axes all show the `_minimal` compared to the legacy performance. `serialize_full` and `save` are unchanged from the legacy version, so speedups are plotted relative to those vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEEDS[[\"grid_n\", \"n_mazes\", \"serialize_minimal:profiling\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEEDS[\"load_minimal:profiling\"][len(SPEEDS) - 1].sort_stats(\"tottime\").print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
