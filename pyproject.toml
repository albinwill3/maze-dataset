[project]
    name = "maze-dataset"
    version = "1.2.0"
    description = "generating and working with datasets of mazes"
    authors = [
        { name = "Michael Ivanitskiy", email = "mivanits@umich.edu" },
        { name = "Aaron Sandoval", email = "aaron.sandoval10@gmail.com" },
        { name = "Rusheb Shah", email = "rusheb.shah@gmail.com" },
        { name = "Dan Valentine", email = "danvalentine256@gmail.com" },
        { name = "Lucia Quirke", email = "luciaq@canva.com" },
        { name = "Can Rager", email = "can.rager@posteo.de" },
        { name = "Alex Spies", email = "alexfspies@gmail.com" },
        { name = "Chris Mathwin", email = "cwmathwin@gmail.com" },
        { name = "Tilman Rauker", email = "traeuker@googlemail.com" },
        { name = "Guillaume Corlouer", email = "guillaume.corlouer@gmail.com" },
    ]
    readme = "README.md"
    requires-python = ">=3.10"

    # source info
    # packages = [{include = "maze_dataset"}]
    # exclude = ["maze_dataset/tokenization/MazeTokenizerModular_hashes.npz"] # don't ship the hashes

    # informational metadata
    keywords = ["maze", "mazes", "labyrinth", "dataset", "procedural", "pathfinding", "tokenization"]


    dependencies = [
        # custom packages
        "muutils>=0.8.3",
        "zanj>=0.4.0",
        # torch and type hints
        "torch>=1.13.1",
        "jaxtyping>=0.2.19",
        # standard numerical
        "matplotlib>=3.7.0",
        "pandas>=2.2.2",
        # notebooks
        "jupyter>=1.0.0",
        "ipykernel>=6.22.0",
        # misc
        "tqdm>=4.65.0",
        "frozendict>=2.4.4",
    ]

[dependency-groups]
	dev = [
		# test
		"pytest>=8.2.2",
        "pytest-xdist>=3.6.1", # for parallel all tokenizers tests
        "pytest-mock>=3.10.0",
		# coverage
		"pytest-cov>=4.1.0",
		"coverage-badge>=1.1.0",
		# type checking
		"mypy>=1.0.1",
        "types-tqdm",
        "pandas-stubs",
		# docs
		'pdoc>=14.6.0',
		"nbconvert>=7.16.4", # for notebooks
		# lmcat -- a custom library. not exactly docs, but lets an LLM see all the code
		"lmcat>=0.2.0; python_version >= '3.11'",
		# tomli since no tomlib in python < 3.11
		"tomli>=2.1.0; python_version < '3.11'",
	]
	lint = [
		# lint
		"pycln>=2.1.3",
		"ruff>=0.4.8",
	]

[project.urls]
    Homepage = "https://github.com/understanding-search/maze-dataset"
    Documentation = "https://understanding-search.github.io/maze-dataset/"
    Repository = "https://github.com/understanding-search/maze-dataset"
    Issues = "https://github.com/understanding-search/maze-dataset/issues"

[build-system]
	requires = ["hatchling"]
	build-backend = "hatchling.build"


[tool.pytest.ini_options]
    # Ignore numpy deprecation warnings triggered by muutils
    filterwarnings = [
        # Warning from muutils: https://github.com/mivanit/muutils/issues/1
        "ignore:`np\\.\\w*` is a deprecated alias for:DeprecationWarning",

        # Warning from matplotlib. Issue: https://github.com/matplotlib/matplotlib/issues/25244
        "ignore:Deprecated call to `pkg_resources.declare_namespace:DeprecationWarning",

        # temporary fix for lots of deprecation warnings for old tokenizers
        "ignore::maze_dataset.token_utils.TokenizerPendingDeprecationWarning",
    ]
    testpaths = "tests"
    norecursedirs="maze_dataset/utils/test_helpers"

[tool.mypy]
    # generate this exclude with `make typing-report`
    exclude = [
        # high priority:
        "maze_dataset/utils.py", # 18
        "maze_dataset/constants.py", # 41
        "tests/unit/maze_dataset/utils.py", # 5
        "maze_dataset/generation/generators.py", # 14
        "maze_dataset/dataset/dataset.py", # 20
        "maze_dataset/dataset/maze_dataset.py", # 41
        "maze_dataset/dataset/collected_dataset.py", # 10
        "maze_dataset/dataset/rasterized.py", # 8
        "maze_dataset/token_utils.py", # 13
        "maze_dataset/plotting/print_tokens.py", # 6
        "maze_dataset/tokenization/all_tokenizers.py", # 7
        # low priority:
        "tests/unit/maze_dataset/dataset/test_collected_dataset.py", # 5
        "tests/unit/maze_dataset/processing/test_collect_gen_metadata.py", # 5
        "tests/unit/maze_dataset/generation/test_latticemaze.py", # 7
        "maze_dataset/benchmark/speed.py", # 8
        "maze_dataset/benchmark/percolation_fractions.py", # 10
        "maze_dataset/plotting/plot_maze.py", # 12
        "tests/all_tokenizers/test_all_tokenizers.py", # 12
        "tests/unit/maze_dataset/tokenization/test_token_utils.py", # 16
        "tests/unit/maze_dataset/generation/test_maze_dataset.py", # 29
        "tests/unit/maze_dataset/tokenization/test_tokenizer.py", # 47
        "tests/unit/maze_dataset/processing/test_get_forking_path_points.py", # 58
        "maze_dataset/tokenization/maze_tokenizer.py", # 135
    ]
    check_untyped_defs = true

    [[tool.mypy.overrides]]
        module = "fire"
        ignore_missing_imports = true

[tool.ruff.lint]
    ignore = [
        "F722"
    ]

[tool.lmcat]
	output = "docs/other/lmcat.txt" # changing this might mean it wont be accessible from the docs
	ignore_patterns = [
		"docs/**",
		".venv/**",
		".git/**",
		".meta/**",
		"uv.lock",
        ".ruff_cache/**",
        ".github/ISSUE_TEMPLATE/**",
        "_wip/**",
        "sweep.yaml",
        # there are... a lot of tests. we usually dont need to put these in lmcat
        "tests/**",
        "*.npz",
	]
    [tool.lmcat.glob_process]
        "[mM]akefile" = "makefile_recipes"
        "*.ipynb" = "ipynb_to_md"

# [tool.pycln]
#     disable-all-dunder-policy = true # this doesn't seem to work... :/

# ============================================================
[tool.makefile]

# documentation configuration, for `make docs` and `make docs-clean`
[tool.makefile.docs]
    # Output directory for generated documentation
    # MUST match DOCS_DIR in makefile
    output_dir = "docs"

    # List of files/directories in docs/ that should not be cleaned by `make docs-clean`
    # These paths are relative to output_dir
    no_clean = [
        ".nojekyll",
        "assets/",
        "benchmarks",
        # "resources/", # Templates, CSS, etc. this, or whatever is specified as DOCS_RESOURCES_DIR in makefile will always be preserved
    ]

    # Increment level of markdown headings in generated documentation
    # e.g. if 2, then h1 -> h3, h2 -> h4, etc.
    markdown_headings_increment = 2

    # Warnings to ignore during documentation generation
    warnings_ignore = [
        "Error parsing type annotation FilterBy for maze_dataset",
        "Found 'coord_str_to_tuple' in maze_dataset.tokenization.__all__, but it does not resolve: Error importing maze_dataset.tokenization.coord_str_to_tuple",
    ]

    # optional generation of notebooks as html pages
    [tool.makefile.docs.notebooks]
        # Enable notebook processing in documentation
		# disabled by default
        enabled = true
        
        # Source directory containing .ipynb files
        source_path = "notebooks"
        
        # Output path relative to docs directory [tool.makefile.docs.output_dir]
        output_path_relative = "notebooks"
        
        # Custom template for notebooks index page
        # Available variables: notebook_url, notebooks (list of dicts with ipynb, html, desc)
        # index_template = ...

        # Descriptions for notebooks, shown in index
        [tool.makefile.docs.notebooks.descriptions]
            "example" = "Example notebook showing basic usage"
            "advanced" = "Advanced usage patterns and techniques"
        
        

# Custom export configurations
# affects `make dep` and related commands
[tool.makefile.uv-exports]
	args = [
		"--no-hashes"
	]
	exports = [
		# no groups, no extras, just the base dependencies
		{ name = "base", groups = false, extras = false },
		# all groups
		{ name = "groups", groups = true, extras = false },
		# only the lint group -- custom options for this
		{ name = "lint", options = ["--only-group", "lint"] },
		# # all groups and extras
		{ name = "all", filename="requirements.txt", groups = true, extras=true },
		# # all groups and extras, a different way
		{ name = "all", groups = true, options = ["--all-extras"] },
	]

# configures `make todo`
[tool.makefile.inline-todo]
	# Directory to search for TODOs
	search_dir = "."
	
	# Output file location (relative to project root)
    # If changed, update docs references
	out_file = "docs/other/todo-inline.md"

	# Number of context lines to include around each TODO
	context_lines = 2

	# File extensions to search
	extensions = ["py", "md"]

	# Tags to look for
	tags = ["CRIT", "TODO", "FIXME", "HACK", "BUG", "DOC"]

	# Patterns to exclude from search
	exclude = [
		"docs/**",
		".venv/**",
		"scripts/get_todos.py",
	]
    
    # configuring the output
	# ------------------------------
	# branch to put in the url
	branch = "main"

	# repo url -- by default this will come from `[project.urls.{repository, github}]`
	# but you can override it here
	# repo_url = ...

    
	
	# template for the markdown output
	# this uses jinja2. see `TEMPLATE_MD` in makefile under `SCRIPT_GET_TODOS`
	# template_md = ...

	# this uses standard python string formatting
	# available variables: file, file_lang, line_num, code_url, context
	# template_issue = ...

	# this template has some custom syntax for adding the data directly to the html file. see that file for more info
	# template_html_source = "docs/resources/templates/todo-template.html"

    # Mapping of tags to GitHub issue labels
    [tool.makefile.inline-todo.tag_label_map]
        "BUG" = "bug"
        "TODO" = "enhancement"
		"DOC" = "documentation"

# ============================================================

